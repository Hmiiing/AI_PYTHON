{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensor manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "t=np.array([0.,1.,2.,3.,4.,5.,6.])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1., 2., 3.],\n",
    "                       [4., 5., 6.],\n",
    "                       [7., 8., 9.],\n",
    "                       [10., 11., 12.]\n",
    "                      ])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------\n",
      "Mul vs Matmul\n",
      "-------------\n",
      "Shape of Matrix 1:  torch.Size([2, 2])\n",
      "Shape of Matrix 2:  torch.Size([2, 1])\n",
      "tensor([[ 5.],\n",
      "        [11.]])\n",
      "Shape of Matrix 1:  torch.Size([2, 2])\n",
      "Shape of Matrix 2:  torch.Size([2, 1])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('-------------')\n",
    "print('Mul vs Matmul')\n",
    "print('-------------')\n",
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print('Shape of Matrix 1: ', m1.shape) # 2 x 2\n",
    "print('Shape of Matrix 2: ', m2.shape) # 2 x 1\n",
    "print(m1.matmul(m2)) # 2 x 1\n",
    "\n",
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print('Shape of Matrix 1: ', m1.shape) # 2 x 2\n",
    "print('Shape of Matrix 2: ', m2.shape) # 2 x 1\n",
    "print(m1 * m2) # 2 x 2\n",
    "print(m1.mul(m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "# Same shape\n",
    "m1 = torch.FloatTensor([[3, 3]])\n",
    "m2 = torch.FloatTensor([[2, 2]])\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([1, 2])\n",
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can only calculate the mean of floating types. Got Long instead.\n"
     ]
    }
   ],
   "source": [
    "# Can't use mean() on integers\n",
    "t = torch.LongTensor([1, 2])\n",
    "try:\n",
    "    print(t.mean())\n",
    "except Exception as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "print(t.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t = np.array([[[0, 1, 2],\n",
    "               [3, 4, 5]],\n",
    "\n",
    "              [[6, 7, 8],\n",
    "               [9, 10, 11]]])\n",
    "ft = torch.FloatTensor(t)\n",
    "print(ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.view([-1, 3]))\n",
    "print(ft.view([-1, 3]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.],\n",
      "         [ 9., 10., 11.]]])\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.squeeze())\n",
    "print(ft.squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  2.],\n",
      "          [ 3.,  4.,  5.]],\n",
      "\n",
      "         [[ 6.,  7.,  8.],\n",
      "          [ 9., 10., 11.]]]])\n",
      "torch.Size([1, 2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.unsqueeze(0))\n",
    "print(ft.unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0]])\n"
     ]
    }
   ],
   "source": [
    "lt = torch.LongTensor([[0], [1], [2], [0]])\n",
    "print(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "one_hot = torch.zeros(4, 3) # batch_size = 4, classes = 3\n",
    "one_hot.scatter_(1, lt, 1)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "tensor([1., 2., 3., 4.])\n",
      "tensor([1, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([1, 0, 0, 1])\n",
      "tensor([1., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "lt = torch.LongTensor([1, 2, 3, 4])\n",
    "print(lt)\n",
    "print(lt.float())\n",
    "bt = torch.ByteTensor([True, False, False, True])\n",
    "print(bt)\n",
    "print(bt.long())\n",
    "print(bt.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n",
      "tensor([[1., 2., 5., 6.],\n",
      "        [3., 4., 7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "y = torch.FloatTensor([[5, 6], [7, 8]])\n",
    "print(torch.cat([x, y], dim=0))\n",
    "print(torch.cat([x, y], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([1, 4])\n",
    "y = torch.FloatTensor([2, 5])\n",
    "z = torch.FloatTensor([3, 6])\n",
    "print(torch.stack([x, y, z]))\n",
    "print(torch.stack([x, y, z], dim=1))\n",
    "print(torch.cat([x.unsqueeze(0), y.unsqueeze(0), z.unsqueeze(0)], dim=0))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [2., 1., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[0, 1, 2], [2, 1, 0]])\n",
    "print(x)\n",
    "print(torch.ones_like(x))\n",
    "print(torch.zeros_like(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(x.mul(2.))\n",
    "print(x)\n",
    "print(x.mul_(2.))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n",
      "2 5\n",
      "3 6\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip([1, 2, 3], [4, 5, 6]):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0/1000,W:0.187,b:0.080,Cost:18.667\n",
      "Epoch: 100/1000,W:1.746,b:0.578,Cost:0.048\n",
      "Epoch: 200/1000,W:1.800,b:0.454,Cost:0.030\n",
      "Epoch: 300/1000,W:1.843,b:0.357,Cost:0.018\n",
      "Epoch: 400/1000,W:1.876,b:0.281,Cost:0.011\n",
      "Epoch: 500/1000,W:1.903,b:0.221,Cost:0.007\n",
      "Epoch: 600/1000,W:1.924,b:0.174,Cost:0.004\n",
      "Epoch: 700/1000,W:1.940,b:0.136,Cost:0.003\n",
      "Epoch: 800/1000,W:1.953,b:0.107,Cost:0.002\n",
      "Epoch: 900/1000,W:1.963,b:0.084,Cost:0.001\n",
      "Epoch:1000/1000,W:1.971,b:0.066,Cost:0.001\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])\n",
    "# 모델 초기화\n",
    "W=torch.zeros(1,requires_grad=True)\n",
    "b=torch.zeros(1,requires_grad=True)\n",
    "#optimizer 설정\n",
    "optimizer=optim.SGD([W,b],lr=0.01)\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    #가설설정\n",
    "    hypothesis = x_train*W+b\n",
    "    #cost계산\n",
    "    cost=F.mse_loss(hypothesis,y_train)\n",
    "    #개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #로그 출력\n",
    "    if epoch % 100 ==0:\n",
    "        print('Epoch:{:4d}/{},W:{:.3f},b:{:.3f},Cost:{:.3f}'.format(epoch,nb_epochs,W.item(),b.item(),cost.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.9497],\n",
       "        [ 9.9205],\n",
       "        [11.8914]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예측해보기\n",
    "x_test=torch.FloatTensor([[4],[5],[6]])\n",
    "predict=x_test*W+b\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### high level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0/1000, W:-0.210,b:0.175,Cost:26.888227462768555\n",
      "Epoch: 100/1000, W:1.668,b:0.756,Cost:0.08232402056455612\n",
      "Epoch: 200/1000, W:1.739,b:0.594,Cost:0.050871238112449646\n",
      "Epoch: 300/1000, W:1.795,b:0.467,Cost:0.03143530339002609\n",
      "Epoch: 400/1000, W:1.839,b:0.367,Cost:0.01942511647939682\n",
      "Epoch: 500/1000, W:1.873,b:0.289,Cost:0.012003554031252861\n",
      "Epoch: 600/1000, W:1.900,b:0.227,Cost:0.0074174487963318825\n",
      "Epoch: 700/1000, W:1.922,b:0.178,Cost:0.004583548288792372\n",
      "Epoch: 800/1000, W:1.938,b:0.140,Cost:0.002832368016242981\n",
      "Epoch: 900/1000, W:1.952,b:0.110,Cost:0.001750220893882215\n",
      "Epoch:1000/1000, W:1.962,b:0.087,Cost:0.0010815331479534507\n"
     ]
    }
   ],
   "source": [
    "#데이터\n",
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])\n",
    "#모델초기화\n",
    "model=LinearRegressionModel()\n",
    "#optimizer설정\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.01)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    prediction = model(x_train)\n",
    "    cost = F.mse_loss(prediction,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100==0:\n",
    "        params=list(model.parameters())\n",
    "        W=params[0].item()\n",
    "        b=params[1].item()\n",
    "        print('Epoch:{:4d}/{}, W:{:.3f},b:{:.3f},Cost:{}'.format(epoch,nb_epochs,W,b,cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.9342],\n",
       "        [ 9.8961],\n",
       "        [11.8580]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예측하기\n",
    "x_test = torch.FloatTensor([[4],[5],[6]])\n",
    "predict = x_test * W + b\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :    0/10, W:0.000,Cost:18.666666\n",
      "Epoch :    1/10, W:2.800,Cost:2.986666\n",
      "Epoch :    2/10, W:1.680,Cost:0.477867\n",
      "Epoch :    3/10, W:2.128,Cost:0.076459\n",
      "Epoch :    4/10, W:1.949,Cost:0.012233\n",
      "Epoch :    5/10, W:2.020,Cost:0.001957\n",
      "Epoch :    6/10, W:1.992,Cost:0.000313\n",
      "Epoch :    7/10, W:2.003,Cost:0.000050\n",
      "Epoch :    8/10, W:1.999,Cost:0.000008\n",
      "Epoch :    9/10, W:2.001,Cost:0.000001\n",
      "Epoch :   10/10, W:2.000,Cost:0.000000\n"
     ]
    }
   ],
   "source": [
    "# gradient\n",
    "x_train=torch.FloatTensor([[1],[2],[3]])\n",
    "y_train=torch.FloatTensor([[2],[4],[6]])\n",
    "W=torch.zeros(1)\n",
    "lr=0.1\n",
    "nb_epochs=10\n",
    "for epoch in range(nb_epochs+1):\n",
    "    hypothesis=W*x_train\n",
    "    cost=F.mse_loss(hypothesis,y_train)\n",
    "    gradient=torch.sum((W*x_train-y_train)*x_train)\n",
    "    print('Epoch : {:4d}/{}, W:{:.3f},Cost:{:.6f}'.format(epoch,nb_epochs,W.item(),cost.item()))\n",
    "    W -= lr*gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multivariate linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epcoh :    0/1000, W1:0.294,W2:0.294,W3:0.297,b:0.003,Cost:29661.800781\n",
      "Epcoh :  100/1000, W1:0.674,W2:0.661,W3:0.676,b:0.008,Cost:1.563634\n",
      "Epcoh :  200/1000, W1:0.679,W2:0.655,W3:0.677,b:0.008,Cost:1.497603\n",
      "Epcoh :  300/1000, W1:0.684,W2:0.649,W3:0.677,b:0.008,Cost:1.435026\n",
      "Epcoh :  400/1000, W1:0.689,W2:0.643,W3:0.678,b:0.008,Cost:1.375730\n",
      "Epcoh :  500/1000, W1:0.694,W2:0.638,W3:0.678,b:0.009,Cost:1.319503\n",
      "Epcoh :  600/1000, W1:0.699,W2:0.633,W3:0.679,b:0.009,Cost:1.266215\n",
      "Epcoh :  700/1000, W1:0.704,W2:0.627,W3:0.679,b:0.009,Cost:1.215693\n",
      "Epcoh :  800/1000, W1:0.709,W2:0.622,W3:0.679,b:0.009,Cost:1.167821\n",
      "Epcoh :  900/1000, W1:0.713,W2:0.617,W3:0.680,b:0.009,Cost:1.122419\n",
      "Epcoh : 1000/1000, W1:0.718,W2:0.613,W3:0.680,b:0.009,Cost:1.079375\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
    "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
    "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "#초기화\n",
    "W1=torch.zeros(1,requires_grad=True)\n",
    "W2=torch.zeros(1,requires_grad=True)\n",
    "W3=torch.zeros(1,requires_grad=True)\n",
    "b=torch.zeros(1,requires_grad=True)\n",
    "#optimizer\n",
    "optimizer=optim.SGD([W1,W2,W3,b],lr=1e-5)\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    hypothesis  = x1_train*W1+x2_train*W2+x3_train*W3+b\n",
    "    cost=F.mse_loss(hypothesis,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 ==0:\n",
    "        print('Epcoh : {:4d}/{}, W1:{:.3f},W2:{:.3f},W3:{:.3f},b:{:.3f},Cost:{:.6f}'.format(epoch,nb_epochs,W1.item(),W2.item(),W3.item(),b.item(),cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch    1/20 hypothesis: tensor([67.2578, 80.8397, 79.6523, 86.7394, 61.6605]) Cost: 9298.520508\n",
      "Epoch    2/20 hypothesis: tensor([104.9128, 126.0990, 124.2466, 135.3015,  96.1821]) Cost: 2915.712646\n",
      "Epoch    3/20 hypothesis: tensor([125.9942, 151.4381, 149.2133, 162.4896, 115.5097]) Cost: 915.040527\n",
      "Epoch    4/20 hypothesis: tensor([137.7968, 165.6247, 163.1911, 177.7112, 126.3307]) Cost: 287.936005\n",
      "Epoch    5/20 hypothesis: tensor([144.4044, 173.5674, 171.0168, 186.2332, 132.3891]) Cost: 91.371017\n",
      "Epoch    6/20 hypothesis: tensor([148.1035, 178.0144, 175.3980, 191.0042, 135.7812]) Cost: 29.758139\n",
      "Epoch    7/20 hypothesis: tensor([150.1744, 180.5042, 177.8508, 193.6753, 137.6805]) Cost: 10.445305\n",
      "Epoch    8/20 hypothesis: tensor([151.3336, 181.8983, 179.2240, 195.1707, 138.7440]) Cost: 4.391228\n",
      "Epoch    9/20 hypothesis: tensor([151.9824, 182.6789, 179.9928, 196.0079, 139.3396]) Cost: 2.493135\n",
      "Epoch   10/20 hypothesis: tensor([152.3454, 183.1161, 180.4231, 196.4765, 139.6732]) Cost: 1.897688\n",
      "Epoch   11/20 hypothesis: tensor([152.5485, 183.3610, 180.6640, 196.7389, 139.8602]) Cost: 1.710541\n",
      "Epoch   12/20 hypothesis: tensor([152.6620, 183.4982, 180.7988, 196.8857, 139.9651]) Cost: 1.651413\n",
      "Epoch   13/20 hypothesis: tensor([152.7253, 183.5752, 180.8742, 196.9678, 140.0240]) Cost: 1.632387\n",
      "Epoch   14/20 hypothesis: tensor([152.7606, 183.6184, 180.9164, 197.0138, 140.0571]) Cost: 1.625923\n",
      "Epoch   15/20 hypothesis: tensor([152.7802, 183.6427, 180.9399, 197.0395, 140.0759]) Cost: 1.623412\n",
      "Epoch   16/20 hypothesis: tensor([152.7909, 183.6565, 180.9530, 197.0538, 140.0865]) Cost: 1.622141\n",
      "Epoch   17/20 hypothesis: tensor([152.7968, 183.6643, 180.9603, 197.0618, 140.0927]) Cost: 1.621253\n",
      "Epoch   18/20 hypothesis: tensor([152.7999, 183.6688, 180.9644, 197.0662, 140.0963]) Cost: 1.620500\n",
      "Epoch   19/20 hypothesis: tensor([152.8014, 183.6715, 180.9666, 197.0686, 140.0985]) Cost: 1.619770\n",
      "Epoch   20/20 hypothesis: tensor([152.8020, 183.6731, 180.9677, 197.0699, 140.1000]) Cost: 1.619033\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "W=torch.zeros((3,1),requires_grad=True)\n",
    "b=torch.zeros(1,requires_grad=True)\n",
    "optimizer = optim.SGD([W,b],lr=1e-5)\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    hypothesis = x_train.matmul(W)+b     # 속도가 빨라짐\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch    1/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch    2/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch    3/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch    4/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch    5/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch    6/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch    7/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch    8/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch    9/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch   10/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch   11/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch   12/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch   13/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch   14/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch   15/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch   16/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch   17/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch   18/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch   19/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n",
      "Epoch   20/20 hypothesis : tensor([-64.4287, -78.7710, -76.8811, -83.6950, -60.5436]) Cost : 60331.523438\n"
     ]
    }
   ],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(3,1)\n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "model = MultivariateLinearRegressionModel()\n",
    "optimizer=optim.SGD([W,b],lr=1e-5)\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    hypothesis = model(x_train)\n",
    "    cost=F.mse_loss(hypothesis,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch {:4d}/{} hypothesis : {} Cost : {:.6f}'.format(epoch,nb_epochs,hypothesis.squeeze().detach(),cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data=[[73,80,75],\n",
    "                    [93,88,93],\n",
    "                    [89,91,90],\n",
    "                    [73,66,70]]\n",
    "        self.y_data=[[152],[185],[180],[196],[142]]\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    def __getitem__(self,idx):\n",
    "        x=torch.FloatTensor(self.x_data[idx])\n",
    "        y=torch.FloatTensor(self.y_data[idx])\n",
    "        return(x,y)\n",
    "        \n",
    "dataset=CustomDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(\n",
    "dataset,\n",
    "batch_size=2,\n",
    "shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/2 Cost:35401.679688\n",
      "Epoch    0/20 Batch 2/2 Cost:42467.171875\n",
      "Epoch    1/20 Batch 1/2 Cost:41328.203125\n",
      "Epoch    1/20 Batch 2/2 Cost:36540.648438\n",
      "Epoch    2/20 Batch 1/2 Cost:43884.644531\n",
      "Epoch    2/20 Batch 2/2 Cost:33984.207031\n",
      "Epoch    3/20 Batch 1/2 Cost:43884.644531\n",
      "Epoch    3/20 Batch 2/2 Cost:33984.207031\n",
      "Epoch    4/20 Batch 1/2 Cost:43884.644531\n",
      "Epoch    4/20 Batch 2/2 Cost:33984.207031\n",
      "Epoch    5/20 Batch 1/2 Cost:41328.203125\n",
      "Epoch    5/20 Batch 2/2 Cost:36540.648438\n",
      "Epoch    6/20 Batch 1/2 Cost:36540.648438\n",
      "Epoch    6/20 Batch 2/2 Cost:41328.203125\n",
      "Epoch    7/20 Batch 1/2 Cost:43884.644531\n",
      "Epoch    7/20 Batch 2/2 Cost:33984.207031\n",
      "Epoch    8/20 Batch 1/2 Cost:43884.644531\n",
      "Epoch    8/20 Batch 2/2 Cost:33984.207031\n",
      "Epoch    9/20 Batch 1/2 Cost:43884.644531\n",
      "Epoch    9/20 Batch 2/2 Cost:33984.207031\n",
      "Epoch   10/20 Batch 1/2 Cost:33984.207031\n",
      "Epoch   10/20 Batch 2/2 Cost:43884.644531\n",
      "Epoch   11/20 Batch 1/2 Cost:41328.203125\n",
      "Epoch   11/20 Batch 2/2 Cost:36540.648438\n",
      "Epoch   12/20 Batch 1/2 Cost:36540.648438\n",
      "Epoch   12/20 Batch 2/2 Cost:41328.203125\n",
      "Epoch   13/20 Batch 1/2 Cost:33984.207031\n",
      "Epoch   13/20 Batch 2/2 Cost:43884.644531\n",
      "Epoch   14/20 Batch 1/2 Cost:33984.207031\n",
      "Epoch   14/20 Batch 2/2 Cost:43884.644531\n",
      "Epoch   15/20 Batch 1/2 Cost:36540.648438\n",
      "Epoch   15/20 Batch 2/2 Cost:41328.203125\n",
      "Epoch   16/20 Batch 1/2 Cost:36540.648438\n",
      "Epoch   16/20 Batch 2/2 Cost:41328.203125\n",
      "Epoch   17/20 Batch 1/2 Cost:42467.171875\n",
      "Epoch   17/20 Batch 2/2 Cost:35401.679688\n",
      "Epoch   18/20 Batch 1/2 Cost:43884.644531\n",
      "Epoch   18/20 Batch 2/2 Cost:33984.207031\n",
      "Epoch   19/20 Batch 1/2 Cost:33984.207031\n",
      "Epoch   19/20 Batch 2/2 Cost:43884.644531\n",
      "Epoch   20/20 Batch 1/2 Cost:33984.207031\n",
      "Epoch   20/20 Batch 2/2 Cost:43884.644531\n"
     ]
    }
   ],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3,1)\n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "model = MultivariateLinearRegressionModel()\n",
    "# 모델 초기화\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    for batch_idx, samples in enumerate(dataloader):   # 배치 사이즈\n",
    "        x_train, y_train = samples\n",
    "        prediction = model(x_train)\n",
    "        cost = F.mse_loss(prediction,y_train)\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        print('Epoch {:4d}/{} Batch {}/{} Cost:{:.6f}'.format(epoch, nb_epochs, batch_idx+1,len(dataloader),cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2545f71d070>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=[[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\n",
    "y_data=[[0],[0],[0],[1],[1],[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [2., 3.],\n",
      "        [3., 1.],\n",
      "        [4., 3.],\n",
      "        [5., 3.],\n",
      "        [6., 2.]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)\n",
    "print(x_train)\n",
    "print(y_train)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost : 0.693147\n",
      "Epoch  100/1000 Cost : 0.134722\n",
      "Epoch  200/1000 Cost : 0.080643\n",
      "Epoch  300/1000 Cost : 0.057900\n",
      "Epoch  400/1000 Cost : 0.045300\n",
      "Epoch  500/1000 Cost : 0.037261\n",
      "Epoch  600/1000 Cost : 0.031672\n",
      "Epoch  700/1000 Cost : 0.027556\n",
      "Epoch  800/1000 Cost : 0.024394\n",
      "Epoch  900/1000 Cost : 0.021888\n",
      "Epoch 1000/1000 Cost : 0.019852\n"
     ]
    }
   ],
   "source": [
    "W=torch.zeros((2,1),requires_grad=True)\n",
    "b=torch.zeros(1,requires_grad=True)\n",
    "optimizer=optim.SGD([W,b],lr=1)\n",
    "nb_epochs=1000\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    hypothesis=torch.sigmoid(x_train.matmul(W)+b)\n",
    "    cost=F.binary_cross_entropy(hypothesis,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch %100==0:\n",
    "        print('Epoch {:4d}/{} Cost : {:.6f}'.format(epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "correct_prediction = prediction.float()==y_train\n",
    "correct_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# higher implementation with class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(2,1)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        return self.sigmoid(self.linear(x))\n",
    "model=BinaryClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100 Cost: 0.539713 Accuracy 83.33%\n",
      "Epoch   10/100 Cost: 0.614853 Accuracy 66.67%\n",
      "Epoch   20/100 Cost: 0.441875 Accuracy 66.67%\n",
      "Epoch   30/100 Cost: 0.373145 Accuracy 83.33%\n",
      "Epoch   40/100 Cost: 0.316358 Accuracy 83.33%\n",
      "Epoch   50/100 Cost: 0.266094 Accuracy 83.33%\n",
      "Epoch   60/100 Cost: 0.220498 Accuracy 100.00%\n",
      "Epoch   70/100 Cost: 0.182095 Accuracy 100.00%\n",
      "Epoch   80/100 Cost: 0.157299 Accuracy 100.00%\n",
      "Epoch   90/100 Cost: 0.144091 Accuracy 100.00%\n",
      "Epoch  100/100 Cost: 0.134272 Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "optimizer=optim.SGD(model.parameters(),lr=1)\n",
    "nb_epochs=100\n",
    "for epoch in range(nb_epochs+1):\n",
    "    hypothesis = model(x_train)\n",
    "    cost=F.binary_cross_entropy(hypothesis,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch %10==0:\n",
    "        prediction = hypothesis >=torch.FloatTensor([0.5])\n",
    "        correct_prediction = prediction.float()==y_train\n",
    "        accuracy = correct_prediction.sum().item()/len(correct_prediction)\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format(epoch,nb_epochs,cost.item(),accuracy*100))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [[1, 2, 1, 1],\n",
    "           [2, 1, 3, 2],\n",
    "           [3, 1, 3, 4],\n",
    "           [4, 1, 5, 5],\n",
    "           [1, 7, 5, 5],\n",
    "           [1, 2, 5, 6],\n",
    "           [1, 6, 6, 6],\n",
    "           [1, 7, 7, 7]]\n",
    "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.LongTensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.098612\n",
      "Epoch  100/1000 Cost: 0.901535\n",
      "Epoch  200/1000 Cost: 0.839114\n",
      "Epoch  300/1000 Cost: 0.807826\n",
      "Epoch  400/1000 Cost: 0.788472\n",
      "Epoch  500/1000 Cost: 0.774822\n",
      "Epoch  600/1000 Cost: 0.764449\n",
      "Epoch  700/1000 Cost: 0.756191\n",
      "Epoch  800/1000 Cost: 0.749398\n",
      "Epoch  900/1000 Cost: 0.743671\n",
      "Epoch 1000/1000 Cost: 0.738749\n"
     ]
    }
   ],
   "source": [
    "#모델초기화\n",
    "W=torch.zeros((4,3),requires_grad=True)\n",
    "b=torch.zeros(1,requires_grad=True)\n",
    "#optimizer 설정\n",
    "optimizer=optim.SGD([W,b],lr=0.1)\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    #cost\n",
    "    hypothesis=F.softmax(x_train.matmul(W)+b,dim=1)\n",
    "    y_one_hot=torch.zeros_like(hypothesis)\n",
    "    y_one_hot.scatter_(1,y_train.unsqueeze(1),1)\n",
    "    cost=(y_one_hot*-torch.log(F.softmax(hypothesis,dim=1))).sum(dim=1).mean()\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
